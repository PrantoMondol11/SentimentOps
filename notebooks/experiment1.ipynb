{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65d7b93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8cdd331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2412acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                 review sentiment\n",
       "0    Every great gangster movie has under-currents ...  positive\n",
       "1    I just saw this film last night, and I have to...  positive\n",
       "2    This film is mildly entertaining if one neglec...  negative\n",
       "3    Quentin Tarantino's partner in crime Roger Ava...  negative\n",
       "4    I sat through this on TV hoping because of the...  negative\n",
       "..                                                 ...       ...\n",
       "495  I was really disappointed by this movie. Great...  negative\n",
       "496  This is a great example of a good, dumb movie....  positive\n",
       "497  Do you know that they want to escavate the Moo...  negative\n",
       "498  I really wanted to like The Pillow Book. Intri...  negative\n",
       "499  Steve Biko was a black activist who tried to r...  positive\n",
       "\n",
       "[500 rows x 2 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbe35977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text=text.split()\n",
    "    text=[lemmatizer.lemmatize(word) for word in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc58b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    text=text.split()\n",
    "    text=[word for word in text if word not in stop_words]\n",
    "    return ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a16936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_numbers(text):\n",
    "    text=\"\".join([i for i in text if not i.isdigit()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfa0d9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_punctuation(text):\n",
    "    text=re.sub('[%s]'% re.escape(string.punctuation),' ',text)\n",
    "    text=re.sub(r\"\\s+\",' ',text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1bdcb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_urls(text):\n",
    "    url_pattern=re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1568e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "    text=text.split()\n",
    "    text=[word.lower() for word in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b89c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(df):\n",
    "    try:\n",
    "        df['review']=df['review'].apply(lower_case)\n",
    "        df['review']=df['review'].apply(removing_urls)\n",
    "        df['review']=df['review'].apply(removing_punctuation)   \n",
    "        df['review']=df['review'].apply(removing_numbers)\n",
    "        df['review']=df['review'].apply(remove_stopwords)\n",
    "        \n",
    "        df['review']=df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in normalize_text: {e}\")\n",
    "        raise\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf8fee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pranto\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3d562fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every great gangster movie current human drama...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saw film last night say loved every minute tak...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film mildly entertaining one neglect acknowled...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin tarantino partner crime roger avary co...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sat tv hoping name would worth time dear gussi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  every great gangster movie current human drama...  positive\n",
       "1  saw film last night say loved every minute tak...  positive\n",
       "2  film mildly entertaining one neglect acknowled...  negative\n",
       "3  quentin tarantino partner crime roger avary co...  negative\n",
       "4  sat tv hoping name would worth time dear gussi...  negative"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44ff6cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    269\n",
       "positive    231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f84bd61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['sentiment'].isin(['positive','negative'])\n",
    "df=df[x]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20d52744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>every great gangster movie current human drama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saw film last night say loved every minute tak...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>film mildly entertaining one neglect acknowled...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quentin tarantino partner crime roger avary co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sat tv hoping name would worth time dear gussi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  every great gangster movie current human drama...          1\n",
       "1  saw film last night say loved every minute tak...          1\n",
       "2  film mildly entertaining one neglect acknowled...          0\n",
       "3  quentin tarantino partner crime roger avary co...          0\n",
       "4  sat tv hoping name would worth time dear gussi...          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']=df['sentiment'].map({'positive':1,'negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4f5accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(max_features=50)\n",
    "x=vectorizer.fit_transform(df['review'])\n",
    "y=df['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b6a1b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04a91427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\pranto\\miniconda3\\envs\\atlas\\lib\\site-packages\\rich\\live.py:260: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\pranto\\miniconda3\\envs\\atlas\\lib\\site-packages\\rich\\live.py:260: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=6bdaf60e-7905-4678-b44b-281989317b8a&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=d3fadc62adeefb7f862537e38194524086f3acf7d49f72ca4eb001c9ed605b34\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as mondolpranto83\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as mondolpranto83\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"mondolpranto83/SentimentOps\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"mondolpranto83/SentimentOps\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository mondolpranto83/SentimentOps initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository mondolpranto83/SentimentOps initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/30 12:39:10 INFO mlflow.tracking.fluent: Experiment with name 'Sentiment_Analysis_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/06b0cbe1d1c8430da760d197216ad29c', creation_time=1769794752953, experiment_id='0', last_update_time=1769794752953, lifecycle_stage='active', name='Sentiment_Analysis_Experiment', tags={}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "mlflow.set_tracking_uri('https://dagshub.com/mondolpranto83/SentimentOps.mlflow')\n",
    "dagshub.init(repo_owner='mondolpranto83',repo_name='SentimentOps',mlflow=True)\n",
    "\n",
    "mlflow.set_experiment('Sentiment_Analysis_Experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "880cb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-30 12:55:55,191 - INFO - Starting model training and evaluation\n",
      "2026-01-30 12:55:55,515 - INFO - Logging preprocessing parameters...\n",
      "2026-01-30 12:55:56,510 - INFO - Initializing and training the Logistic Regression model...\n",
      "2026-01-30 12:55:56,532 - INFO - Model training completed.\n",
      "2026-01-30 12:55:56,837 - INFO - Making pred .......\n",
      "2026-01-30 12:55:56,839 - INFO - Evaluating model performance...\n",
      "2026-01-30 12:55:56,882 - INFO - Saving and logging metrics...\n",
      "2026-01-30 12:55:58,358 - INFO - Logging the trained model...\n",
      "2026/01/30 12:55:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Users\\pranto\\miniconda3\\envs\\atlas\\lib\\site-packages\\mlflow\\models\\model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\n",
      "  flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "2026-01-30 12:56:13,467 - INFO - Total time taken: 17.95179533958435 seconds\n",
      "2026-01-30 12:56:13,467 - INFO - Model training and evaluation completed successfully.\n",
      "2026-01-30 12:56:13,477 - INFO - Accuracy: 0.68, Precision: 0.7142857142857143, Recall: 0.6, F1 Score: 0.6521739130434783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run aged-kit-215 at: https://dagshub.com/mondolpranto83/SentimentOps.mlflow/#/experiments/0/runs/b18afa07acf643b1973cbfe274683da4\n",
      "üß™ View experiment at: https://dagshub.com/mondolpranto83/SentimentOps.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score \n",
    "\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.info(\"Starting model training and evaluation\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    Start_time=time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param('vectorizer','Bag of words')\n",
    "        mlflow.log_param('vectorizer_max_features',50)\n",
    "        mlflow.log_param('test_size',0.2)\n",
    "        \n",
    "        logging.info(\"Initializing and training the Logistic Regression model...\")\n",
    "        model=LogisticRegression(max_iter=1000)\n",
    "        model.fit(x_train,y_train)\n",
    "        logging.info(\"Model training completed.\")\n",
    "        mlflow.log_param('model','Logistic Regression') \n",
    "        logging.info(\"Making pred .......\")\n",
    "        \n",
    "        logging.info(\"Evaluating model performance...\")\n",
    "        y_pred=model.predict(x_test)\n",
    "        accuracy=accuracy_score(y_test,y_pred)\n",
    "        precision=precision_score(y_test,y_pred)\n",
    "        recall=recall_score(y_test,y_pred)\n",
    "        f1=f1_score(y_test,y_pred)\n",
    "        logging.info(\"Saving and logging metrics...\")\n",
    "        \n",
    "        mlflow.log_metric('accuracy',accuracy)\n",
    "        mlflow.log_metric('precision',precision)\n",
    "        mlflow.log_metric('recall',recall)\n",
    "        mlflow.log_metric('f1_score',f1)\n",
    "        \n",
    "        logging.info(\"Logging the trained model...\")\n",
    "        mlflow.sklearn.log_model(model,'sentiment_analysis_model')\n",
    "        \n",
    "        end_time=time.time()\n",
    "        elapsed_time=end_time - Start_time\n",
    "        logging.info(f\"Total time taken: {elapsed_time} seconds\")\n",
    "               \n",
    "        logging.info(\"Model training and evaluation completed successfully.\")\n",
    "        logging.info(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\",exc_info=True)\n",
    "        raise\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b040353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
